\documentclass[reprint,english,notitlepage]{revtex4-1}  % defines the basic parameters of the document

% if you want a single-column, remove reprint

% allows special characters (including æøå)
\usepackage[utf8]{inputenc}
\usepackage[english]{babel}

%% note that you may need to download some of these packages manually, it depends on your setup.
%% I recommend downloading TeXMaker, because it includes a large library of the most common packages.

\usepackage{physics,amssymb}  % mathematical symbols (physics imports amsmath)
\usepackage{graphicx}         % include graphics such as plots
\usepackage{xcolor}           % set colors
\usepackage{hyperref}         % automagic cross-referencing (this is GODLIKE)
\usepackage{tikz}             % draw figures manually
\usepackage{listings}         % display code
\usepackage{subfigure}        % imports a lot of cool and useful figure commands

% defines the color of hyperref objects
% Blending two colors:  blue!80!black  =  80% blue and 20% black
\hypersetup{ % this is just my personal choice, feel free to change things
    colorlinks,
    linkcolor={red!50!black},
    citecolor={blue!50!black},
    urlcolor={blue!80!black}}
    
%% Defines the style of the programming listing
%% This is actually my personal template, go ahead and change stuff if you want
\lstnewenvironment{python}{
	\lstset{ %
		inputpath=,
		backgroundcolor=\color{white!88!black},
		basicstyle={\ttfamily\scriptsize},
		commentstyle=\color{magenta},
		language=Python,
		morekeywords={True,False},
		tabsize=4,
		stringstyle=\color{green!55!black},
		frame=single,
		keywordstyle=\color{blue},
		showstringspaces=false,
		columns=fullflexible,
		keepspaces=true}
}{}

\lstnewenvironment{cpp}{
	\lstset{ %
		inputpath=,
		backgroundcolor=\color{white!88!black},
		basicstyle={\ttfamily\scriptsize},
		commentstyle=\color{magenta},
		language=C++,
		morekeywords={True,False},
		tabsize=4,
		stringstyle=\color{green!55!black},
		frame=single,
		keywordstyle=\color{blue},
		showstringspaces=false,
		columns=fullflexible,
		keepspaces=true}
}{}

\lstset{literate=
  {á}{{\'a}}1 {é}{{\'e}}1 {í}{{\'i}}1 {ó}{{\'o}}1 {ú}{{\'u}}1
  {Á}{{\'A}}1 {É}{{\'E}}1 {Í}{{\'I}}1 {Ó}{{\'O}}1 {Ú}{{\'U}}1
  {à}{{\`a}}1 {è}{{\`e}}1 {ì}{{\`i}}1 {ò}{{\`o}}1 {ù}{{\`u}}1
  {À}{{\`A}}1 {È}{{\'E}}1 {Ì}{{\`I}}1 {Ò}{{\`O}}1 {Ù}{{\`U}}1
  {ä}{{\"a}}1 {ë}{{\"e}}1 {ï}{{\"i}}1 {ö}{{\"o}}1 {ü}{{\"u}}1
  {Ä}{{\"A}}1 {Ë}{{\"E}}1 {Ï}{{\"I}}1 {Ö}{{\"O}}1 {Ü}{{\"U}}1
  {â}{{\^a}}1 {ê}{{\^e}}1 {î}{{\^i}}1 {ô}{{\^o}}1 {û}{{\^u}}1
  {Â}{{\^A}}1 {Ê}{{\^E}}1 {Î}{{\^I}}1 {Ô}{{\^O}}1 {Û}{{\^U}}1
  {œ}{{\oe}}1 {Œ}{{\OE}}1 {æ}{{\ae}}1 {Æ}{{\AE}}1 {ß}{{\ss}}1
  {ű}{{\H{u}}}1 {Ű}{{\H{U}}}1 {ő}{{\H{o}}}1 {Ő}{{\H{O}}}1
  {ç}{{\c c}}1 {Ç}{{\c C}}1 {ø}{{\o}}1 {å}{{\r a}}1 {Å}{{\r A}}1
  {€}{{\euro}}1 {£}{{\pounds}}1 {«}{{\guillemotleft}}1
  {»}{{\guillemotright}}1 {ñ}{{\~n}}1 {Ñ}{{\~N}}1 {¿}{{?`}}1
}



\usepackage{thmtools}
\DeclareMathOperator{\nullspace}{Nul}
\DeclareMathOperator{\collspace}{Col}
\DeclareMathOperator{\rref}{Rref}
%%\DeclareMathOperator{\dim}{Dim}

 % "meq": must be equal
\newcommand{\meq}{\overset{!}{=}}

\newcommand{\R}{\mathbb{R}}
\newcommand*\Heq{\ensuremath{\overset{\kern2pt L'H}{=}}}
\usepackage{bm}
\newcommand{\uveci}{{\bm{\hat{\textnormal{\bfseries\i}}}}}
\newcommand{\uvecj}{{\bm{\hat{\textnormal{\bfseries\j}}}}}
\DeclareRobustCommand{\uvec}[1]{{%
  \ifcsname uvec#1\endcsname
     \csname uvec#1\endcsname
   \else
    \bm{\hat{\mathbf{#1}}}%
   \fi
}}
\usepackage[binary-units=true]{siunitx}

\makeatletter
\newcommand*{\balancecolsandclearpage}{%
  \close@column@grid
  \cleardoublepage
  \twocolumngrid
}
\makeatother

\newcounter{subproject}
\renewcommand{\thesubproject}{\alph{subproject}}
\newenvironment{subproj}{
\begin{description}
	\item[\refstepcounter{subproject}(\thesubproject)]
}{\end{description}}


\begin{document}
\title{On the implementation and usage of Jacobi's rotational algorithm to solve the buckling beam problem, as well as the ground-state energies of a one-electron and two-electron quantum dot system.}   % self-explanatory
\author{Eivind Støland, Anders P. Åsbø}               % self-explanatory
\date{\today}                             % self-explanatory
\noaffiliation                            % ignore this
\maketitle                                % creates the title, author, date


\tableofcontents

\section{Introduction} \label{sec:I}

Some of the most important physical problems can be formulated numerically as eigenvalue problems. Thus being able find eigenvalues and eigenvectors numerically is of critical importance. In this report we study the Jacobi rotation method, and discuss its merits and failings. We also apply it on three different problems, namely that of a buckling beam, and that of one and two electrons in a quantum harmonic oscillator potential. In general this method is applicable to any physical problem which can be formulated as an eigenvalue problem with a symmetrical matrix. 

These three problems showcase some key differences, however. The buckling beam problem results in a Toeplitz matrix, which makes it easier to use this problem to test how well the method works. The single electron in a quantum harmonic oscillator potential results in the diagonal elements of the matrix no longer being constant, and the problem with two electrons result in yet more complex diagonal elements because of the Coulomb interaction between the electrons. This creates some specific error sources that we discuss in detail in \hyperref[sec:III:b]{section III.B.}

Precision of the solutions is key, and thus we test the accuracy of the result against analytical answers for all three problems. For the buckling beam we compare the first numerical eigenvector against the analytical one, and in the two quantum harmonic oscillator problems we compare numerical and analytical eigenvalues. We also make an estimate on how many FLOPs at most which will be needed in order for the solution to converge. This lets us evaluate the computational cost of the method. 

\section{Formalism} \label{sec:II}

\subsection{Unitary transformations and eigenvalues} \label{sec:II:a}

We define a unitary transformation of a matrix \textbf{A} into a matrix \textbf{B} as:

\begin{align*}
\textbf{B} = \textbf{U}^T \textbf{AU} \, ,
\end{align*}

where \textbf{U} is a unitary matrix ($\textbf{U}^T\textbf{U} = \textbf{I}$, where \textbf{I} is the identity matrix). This type of transformation will preserve the eigenvalues of the system, meaning that \textbf{A} and \textbf{B} share the same eigenvalues. This can be seen by manipulating the eigenvalue equation for \textbf{A}:

\begin{align*}
\textbf{A}\textbf{v} = \lambda \textbf{v} \, , 
\end{align*} 

where $\lambda$ is the eigenvalue belonging to eigenvector \textbf{v}. We multiply by $\textbf{U}^T$ from the left and add the identity matrix in between \textbf{A} and \textbf{x}, and use that $\textbf{U}^T \textbf{U} = \textbf{UU}^T$:

\begin{align*}
\textbf{U}^T \textbf{AIv} &= \lambda \textbf{U}^T \textbf{v} \\
\textbf{U}^T \textbf{AU}^T \textbf{Uv} &= \lambda \textbf{U}^T \textbf{v} \\
(\textbf{U}^T \textbf{AU} ) (\textbf{U}^T \textbf{v}) &= \lambda (\textbf{U}^T \textbf{v}) \\
\textbf{Bw} &= \lambda \textbf{w} \, ,
\end{align*}

where we have defined $\textbf{w} = \textbf{U}^T \textbf{v}$. This is now an eigenvalue equation for \textbf{B} with $\lambda$ as the eigenvalue belonging to eigenvector \textbf{w}. This shows that the eigenvalues of the matrix is preserved through a unitary transformation.

A unitary transformation of on orthogonal set of vectors $\textbf{v}_i$ will conserve the orthogonality of the set of vectors. We show this by writing down the transformed set of vectors as:

\begin{align*}
\textbf{w}_i &= \textbf{U} \textbf{v}_i \, ,
\end{align*}

where $U$ is a unitary matrix. We need to check that $\textbf{w}_i^T \textbf{w}_j = \delta_{ij}$ for arbitrary $i$ and $j$:

\begin{align*}
\textbf{w}_i^T \textbf{w}_j &= (\textbf{U}\textbf{v}_i)^T (\textbf{U}\textbf{v}_j) \\
&= \textbf{v}_i^T \textbf{U}^T \textbf{U} \textbf{v}_j \\
&= \textbf{v}_i^T \textbf{v}_j \\
&= \delta_{ij} \, ,
\end{align*}

where we have used that $\textbf{U}$ is a unitary matrix and the orthogonality of the set of vectors $\vec{v}_i$. This shows that during a unitary transformation of a matrix the orthogonality of the eigenvectors is preserved. 


\subsection{Jacobi rotation method} \label{sec:II:b}

One method based on such unitary transformations is the Jacobi rotation method \citep{Jacobi1846}. We perform a series of unitary transformations of a matrix \textbf{A} until it is a diagonal matrix \textbf{D}:

\begin{align*}
\textbf{D} &= \textbf{U}_n^T ... \textbf{U}_1^T \textbf{AU}_1 ... \textbf{U}_n^T
\end{align*}  

As we have already seen that such transformations preserve the eigenvalues and the eigenvectors of \textbf{A}, we automatically have that the diagonal elements of \textbf{D} are the eigenvalues of \textbf{A}. As the eigenvectors of \textbf{D} are the standard basis vectors $\textbf{e}_i$, we can also use this to find the eigenvectors of \textbf{A}, $\textbf{v}_i$. In order to do this we note that:

\begin{align*}
\textbf{e}_i &= \textbf{U}_n^T ... \textbf{U}_1^T \textbf{v}_i \\
\textbf{U}_1 ... \textbf{U}_n \textbf{e}_i &= \textbf{U}_1 ... \textbf{U}_n \textbf{U}_n^T ... \textbf{U}_1^T \textbf{v}_i \\
\textbf{U}_1 ... \textbf{U}_n \textbf{e}_i &= \textbf{v}_i \, ,
\end{align*}

and in this way we can also find the eigenvectors of \textbf{A}. In general this is done as an iterative method were we get closer to a diagonal matrix with every iteration. The iteration is cut off once all the elements not on the diagonal are less than a specified tolerance. 

For the specifics of how this method is performed, including the unitary matrices used we refer to \citep{Hjorth-Jensen2015}. One important thing to note is that this method requires the matrix \textbf{A} to be symmetric. 

We will now present three problems based on one-dimensional wave equations. These can be recast into eigenvalue problems and in so doing we change them into something we can solve using the Jacobi rotation method. We can use the analytical solutions of these problems to verify the accuracy of the method.


\subsection{Buckling beam problem} \label{sec:II:c}

The buckling beam problem is one such problem. The equation is given by:

\begin{align*}
\gamma \frac{d^2 u }{dx^2} &= -Fu(x) \, ,
\end{align*}

where $u(x)$ is the displacement of the beam in the $y$ diretion, $F$ is a force applied at one of the ends of the beam, and $\gamma$ is a parameter defined by properties of the beam. We call the length of the beam $L$, which means that $x\in [0,L]$. We can set up a dimensionless variable $\rho = x/L$, where $\rho \in [0,1]$. This can be inserted into the equation:

\begin{align*}
\frac{\gamma}{L^2} \frac{d^2  }{d\rho^2} u(\rho) &= -Fu(\rho) \\
\frac{d^2}{d\rho^2} u(\rho) &= -\frac{FL^2}{\gamma} u(\rho)
\end{align*}

We define $\lambda = \frac{FL^2}{\gamma}$, which gives us the simplified equation:

\begin{align*}
- \frac{d^2}{d\rho^2} u(\rho) &= \lambda u (\rho)
\end{align*}

We apply Dirichlet boundary conditions $u(\rho_0) = u(\rho_\text{max}) = 0$ and discretize the equation by defining a set of points $\rho_i = \rho_0 + ih$, where $i = 1,2,...,N$ and $h = \frac{\rho_\text{max} - \rho_0}{N}$. We already know from the definition of $\rho$ that $\rho_0 = 0$ and $\rho_\text{max} = 1$. We can approximate the derivative in the equation:

\begin{align*}
\frac{d^2}{d\rho^2} u(\rho) &=  \frac{u(\rho+h) - 2u (\rho)  + u(\rho - h) }{h^2} + \mathcal{O}(h^2)  \, ,
\end{align*}

where we select $N$ so that $h$ is small enough such that we can neglect the higher order terms $\mathcal{O}(h^2)$. We use this approximation along with our discretization to rewrite the equation:

\begin{align*}
-\frac{u_{i+1} - 2u_i + u_{i-1}}{h^2} &= \lambda u_i \, ,
\end{align*} 

where $u_i = u(\rho_i)$. This can be rewritten as an eigenvalue problem:

\begin{align*}
\textbf{Au} = \lambda \textbf{u} \, ,
\end{align*}

where $\textbf{u}$ contains the $u_i$ with $i = 1,...,N-1$ (the boundary conditions fixes $u_0$ and $u_N$) and $\textbf{A}$ is a tridiagonal matrix with diagonal elements:

\begin{align*}
d = -\frac{2}{h^2}
\end{align*}

and elements in the bands above and below the diagonal:

\begin{align*}
e = \frac{1}{h^2}
\end{align*}

In other words the matrix takes the form:

\begin{align*}
\textbf{A} = \begin{bmatrix}
d & e & 0 & \cdots  & \cdots & \cdots & 0  \\
e & d & e & 0 & \cdots & 0 & 0 \\
0 & e & d & e & 0 & \cdots & 0 \\
\vdots & \vdots & \ddots & \ddots & \ddots & \vdots &  \vdots \\
\vdots & \vdots & 0 & e & d & e & 0 \\
0 & \cdots & \cdots & 0 & e & d & e \\
0 & \cdots & \cdots & \cdots & 0 & e & d 
\end{bmatrix}
\end{align*}

Thus by finding the eigenvalues and eigenvectors of $\textbf{A}$ we can solve the buckling beam problem. The analytical eigenvalues of this matrix are:

\begin{align*}
\lambda_j &= d + 2a \cos ( \frac{j\pi}{N}) \quad , \quad j = 1,2,...,N-1 \, ,
\end{align*}

and the eigenvectors are:

\begin{align*}
\textbf{u}_j &= \begin{bmatrix}
\sin( \frac{j\pi}{N} ) \\
\sin( \frac{2j\pi}{N} ) \\
\vdots \\
\sin( \frac{(N-1)j\pi}{N} ) 
\end{bmatrix} \quad , \quad j = 1,2,...,N-1
\end{align*}

These can be compared with our numerical results. The derivation of this analytical solution is detailed in \citep{Lyche2017}. 



\subsection{Quantum mechanical harmonic oscillator with one electron as an eigenvalue problem} \label{sec:II:d}

The harmonic oscillator potential is central symmetric. This means that the Schrödinger equation can be split into a radial part and an angular part, where the angular part has an analytic solution. We ignore this part of the equation and instead focus only on the radial part:

\begin{align*}
-\frac{\hbar^2}{2m} \bigg( \frac{1}{r^2} \frac{d}{dr}r^2 \frac{d}{dr} - \frac{l(l+1)}{r^2} \bigg) R(r) + \frac{1}{2}kr^2 R(r) = ER(r) \, ,
\end{align*} 

where $k = m\omega^2$ with $\omega$ being the oscillator frequency and $m$ being the mass. $r$ is the radial coordinate, $l$ is the angular momentum quantum number, $R(r)$ is the radial part of the wave equation, and $E$ is the energy. We can substitute $R(r) = u(r)/r$ which simplifies the equation:

\begin{align*}
-\frac{\hbar^2}{2m} \frac{d^2}{dr^2} u(r) + \bigg( \frac{1}{2}kr^2 + \frac{l(l+1)}{r^2} \frac{\hbar^2}{2m} \bigg) u(r) &= Eu(r) \, ,
\end{align*}

where we have separated the differential from the rest of the equation as well, which will be useful later on. To further simplify we can scale the equation. We do this by introducing a dimensionless variable $\rho = r/\alpha$, where $\alpha$ is a constant. Inserting this gives:

\begin{align*}
-\frac{\hbar^2}{2m\alpha^2} \frac{d^2}{d\rho^2} u(\rho) + \bigg( \frac{1}{2}k\alpha^2 \rho^2 + \frac{l(l+1)}{\rho^2} \frac{\hbar^2}{2m\alpha^2} \bigg) u(\rho) &= Eu(\rho) 
\end{align*}

From here on out we will assume the system to be in the lowest orbital state ($l=0$), which simplifies the equation above furter:

\begin{align*}
-\frac{\hbar^2}{2m\alpha^2} \frac{d^2}{d\rho^2} u(\rho) + \frac{1}{2}k\alpha^2 \rho^2 u(\rho) &= Eu(\rho) 
\end{align*}

We multiply by $\frac{2m\alpha^2}{\hbar^2}$ on both sides:

\begin{align*}
-\frac{d^2}{d\rho^2} u(\rho) + \frac{mk}{\hbar^2}\alpha^4 \rho^2 u(\rho) &= \frac{2m\alpha^2}{\hbar^2} Eu(\rho) 
\end{align*}

As $\alpha$ is an arbitrary constant we can choose $\alpha = \sqrt{\frac{\hbar}{m \omega}}$, and define $\lambda = \frac{2m\alpha^2}{\hbar^2} E = \frac{2}{\hbar \omega} E$:

\begin{align*}
-\frac{d^2}{d\rho^2} u(\rho) + \rho^2 u(\rho) &= \lambda u(\rho) 
\end{align*}

We know that the allowed energy levels for a quantum harmonic oscillator are $E_n = \hbar \omega (n + \frac{1}{2})$, which gives us that $\lambda_n = 2n+1$. This can be compared with a numerical calculation later to check the accuracy of our results.
 
In general we have that $u(0) = u(\infty) = 0$. This is not feasible on a computer and as such we define a $\rho_{\text{max}}$ and set boundary conditions $u(0) = u(\rho_{\text{max}}) = 0$. We then define a set of points $\rho_i = \rho_0 + ih$ where $i = 1,2,...,N$ and $h = \frac{\rho_N - \rho_0}{N}$, and set $\rho_0 = 0$ and $\rho_N  = \rho_{\text{max}}$. These points can be used to discretize the previous equation (approximating the derivative as well):

\begin{align*}
\frac{-u_{i+1} + 2u_i - u_{i-1}}{h^2} + \rho_i^2 u_i = \lambda u_i \, ,
\end{align*}

where $u_i = u(\rho_i)$. This can be set up as an eigenvalue problem:

\begin{align*}
\textbf{Au} = \lambda \textbf{u} \, ,
\end{align*}

where $\textbf{u}$ contains all the $u_i$. The matrix \textbf{A} will have diagonal elements:

\begin{align*}
d_i = \frac{2}{h^2} + \rho_i^2 \, ,
\end{align*}

and elements above and below the diagonal:

\begin{align*}
e = -\frac{1}{h^2}
\end{align*}

We can now use numerical methods such as the Jacobi rotation algorithm to find the eigenvalues and eigenvectors (solutions) of \textbf{A} as it is a symmetrical matrix.


\subsection{Quantum mechanical harmonic oscillator with two electrons as an eigenvalue problem} \label{sec:II:e}
 
Similarly to how we did in the previous section we can find a numerical solution to the Schrödinger equation where we have two electrons in a harmonic oscillator instead of one. As the electrons can interact we now need to add the Coulomb potential to the equation. We ignore this for now, but will add it later. The radial part of the Schrödinger equation with two electrons in a harmonic oscillator is (where some of the steps from the previous section has already been applied):

\begin{align*}
\bigg( -\frac{\hbar^2}{2m} \frac{d^2}{dr_1^2} - \frac{\hbar^2}{2m} \frac{d^2}{dr_2^2} + \frac{1}{2}kr_1^2 + \frac{1}{2}kr_2^2 \bigg) u(r_1,r_2) =  Eu(r_1,r_2) \, ,
\end{align*}

where $E$ now is the total energy of the system. Inserting the relative coordinate $\textbf{r} = \textbf{r}_1 - \textbf{r}_2$ and the center-of-mass coordinate $\textbf{R} = \frac{\textbf{r}_1 + \textbf{r}_2}{2}$ gives us:

\begin{align*}
\bigg( -\frac{\hbar^2}{m} \frac{d^2}{dr^2} - \frac{\hbar^2}{4m} \frac{d^2}{dR^2} + \frac{1}{4}kr^2 + kR^2\bigg) u(r,R) &= Eu(r,R)
\end{align*}

This can be separated again into an $R$-dependent and an $r$-dependent part by setting $u(r,R) = \psi(r) \phi(R)$ and separating the energy into $E = E_r + E_R$. The $R$-dependent part is essentially the same problem we discussed in the previous section and so we discuss only the $r$-dependent part from here on out.

The Coulomb potential is given by $V(r) = \frac{\beta e^2}{r}$, where $\beta e^2 = 1.44$ eV nm. We add this to the equation:

\begin{align*}
\bigg( - \frac{\hbar^2}{m} \frac{d^2}{dr^2} + \frac{1}{4}kr^2 + \frac{\beta e^2}{r} \bigg) \psi(r) = E_r \psi(r)
\end{align*}

Again we introduce the dimensionless variable $\rho = r/\alpha$ and multiply by $\frac{m\alpha^2}{\hbar^2}$ on both sides of the equation:

\begin{align*}
\bigg( - \frac{d^2}{d\rho^2} + \frac{1}{4} \frac{mk}{\hbar^2} \alpha^4 \rho^2 + \frac{m\alpha \beta e^2}{\rho \hbar^2} \bigg) \psi (\rho) &= \frac{m\alpha^2}{\hbar^2} E_r \psi(\rho)
\end{align*} 

We define $\omega_r^2 = \frac{1}{4} \frac{mk}{\hbar^2} \alpha^4$ and $\lambda = \frac{m\alpha^2}{\hbar^2}E_r$, and set $\alpha = \frac{\hbar^2}{m\beta e^2}$. The equation can then be rewritten into:

\begin{align*}
- \frac{d^2}{d\rho^2} \psi(\rho) + \omega_r^2 \rho^2 \psi(\rho) + \frac{1}{\rho} \psi(\rho) = \lambda \psi(\rho)
\end{align*}

This equation has analytical solutions (detailed in \citep{PhysRevA.48.3561}) for $\lambda$:

\begin{align*}
\lambda_i &= 3 \omega_r^{3/2} +\sqrt{3} \omega_r (2i + 1)
\end{align*}

The boundary conditions will be the same as in the previous section, and we define the same discretization. This gives us:

\begin{align*}
\frac{-u_{i+1} + 2u_i - u_{i-1}}{h^2} + \bigg( \omega_r^2\rho_i^2 + \frac{1}{\rho_i} \bigg) u_i = \lambda u_i 
\end{align*}

This can be set up as an eigenvalue problem in the same way as in the previous section:

\begin{align*}
\textbf{Au} = \lambda \textbf{u} \, ,
\end{align*}

where the diagonal elements in \textbf{A} are given by:

\begin{align*}
d_i &= \frac{2}{h^2} + \omega_r^2 \rho_i^2 + \frac{1}{\rho_i}
\end{align*}

and the elements above and below the diagonal are:

\begin{align*}
e &= - \frac{1}{h^2}
\end{align*}

This can similarly be solved using the Jacobi rotation method as the matrix is symmetric.

\newpage


\section{Method} \label{sec:III}

\subsection{Implementation of Jacobi rotation algorithm} \label{sec:III:a}

We have implemented the Jacobi rotation algorithm as a class in C++. The code is linked to in \hyperref[A]{appendix A}. It is instantiated with two Armadillo \citep{Armadillo} matrices \textbf{A} and \textbf{R} and the dimensionality of the matrices as an integer \verb+N+. It is worth noting that this is not the same $N$ defined in the \hyperref[sec:II]{section II}, as the dimensionality of the matrices is one less than $N$. At input the matrix \textbf{A} is the matrix for which we want to calculate eigenvalues and eigenvectors and \textbf{R} should be the identity matrix, but can be any matrix with the same dimensionality as \textbf{A} as the class sets it up correctly anyway. Running the \verb+solve()+ method belonging to the class will replace the elements in \textbf{A} and \textbf{R} such that the diagonal elements of \textbf{A} will be the eigenvalues and the columns of \textbf{R} will be the eigenvectors. 

The \verb+solve()+ method performs the following while-loop:

\begin{cpp}
double epsilon = 1.0e-8; 
double max_number_iterations = double(N)*double(N)*double(N);
int iterations = 0;
double max_off_diag = max_offdiag();
while ( fabs(max_off_diag)>epsilon &&
        double(iterations)<max_number_iterations){
    max_off_diag = max_offdiag();
    rotate();
    iterations++;
}
\end{cpp}

A tolerance \verb+epsilon+ is set, along with a cap on the number of iterations, \verb+max_number_iterations+. For every iteration it checks whether the pivot element (the largest element not on the diagonal) is larger than the tolerance and that the cap on iterations has not been reached yet. In every iteration we get the pivot element using \verb+max_offdiag()+ and the \verb+rotate()+ function, which performs one transformation of the matrix, is called. 

The \verb+max_offdiag()+ function works as follows:

\begin{cpp}
double max = 0.0;
for(int i = 0; i < N; i++ ){
  for(int j = i + 1; j < N; j++ ){
    if( fabs((*A)(i,j)) > max ){
      max = fabs((*A)(i,j));
      l = i;
      k = j;
    }
  }
}
\end{cpp}

It simply checks all the elements in the upper triangular part of the matrix and finds the largest element. The largest element is stored in \verb+max+ and is returned by the function. The indices of the element is also stored in the integers \verb+k+ and \verb+l+ which are stored internally in the class.

The \verb+rotate()+ function works as follows:

\begin{cpp}
double s,c;
if ((*A)(k,l) != 0.0){
  double t,tau;
  tau = ((*A)(l,l)- (*A)(k,k))/(2*(*A)(k,l));
  if (tau > 0){
    t = 1.0/(tau + sqrt(1.0 + tau*tau));
  }
  else {
    t = -1.0/(-tau + sqrt(1.0 + tau*tau));
  }
  c = 1.0/sqrt(1+t*t);
  s = c*t;
}
else {
  c = 1.0;
  s = 0.0;
}

double a_kk, a_ll, a_ik, a_il, r_ik, r_il;
a_kk = (*A)(k,k);
a_ll = (*A)(l,l);

(*A)(k,k) = c*c*a_kk - 2.0*c*s*(*A)(k,l) + s*s*a_ll;
(*A)(l,l) = s*s*a_kk + 2.0*c*s*(*A)(k,l) + c*c*a_ll;
(*A)(k,l) = 0.0; // hard-coding of the zeros
(*A)(l,k) = 0.0;

for (int i = 0; i<N; ++i){
  if (i != k && i != l) {
    a_ik = (*A)(i,k);
    a_il = (*A)(i,l);
    (*A)(i,k) = c*a_ik - s*a_il;
    (*A)(k,i) = (*A)(i,k);
    (*A)(i,l) = c*a_il + s*a_ik;
    (*A)(l,i) = (*A)(i,l);
  }

  r_ik = (*R)(i,k);
  r_il = (*R)(i,l);
  (*R)(i,k) = c*r_ik - s*r_il;
  (*R)(i,l) = c*r_il + s*r_ik;
}
\end{cpp}

First it calculates the variables \verb+s+ and \verb+c+. These variables are as outlined in \citep{Hjorth-Jensen2015}. Then it performs the rotation by calculating the new elements of \verb+A+ and \verb+R+ and replacing the old ones.

\subsubsection{Computational cost} \label{sec:III:a:i}

For each rotation we need to update the matrix elements of \textbf{A} and \textbf{R}. This takes $12N$ FLOPs total, where $N$ is the dimensionality of the matrix. In addition to this there are 29 FLOPs outside of the loop in the rotate function, meaning that for each rotation we have about $O(N) = 12N + 29$ FLOPs. Now we need to figure out an expression for how fast the solution converges, in order to determine the total amount of FLOPs for the algorithm. To this end we define:

\begin{align*}
\text{off}(\textbf{A})^2 &= \sum\limits_{ij} |a_{ij}|^2 \, ,
\end{align*}

where $a_{ij}$ are the components of matrix \textbf{A}. We define the pivot element $p$ as the largest element in the matrix:

\begin{align*}
|p| = |\text{max}(a_{ij})|
\end{align*}

There are $N(N-1)$ elements not on the diagonal in the matrix, which means that at all times we have:

\begin{align*}
\text{off}(\textbf{A})^2 \leq N(N-1)|p|^2 \\
\frac{\text{off}(\textbf{A})^2}{N(N-1)} \leq |p|^2
\end{align*}

For each rotation we reduce $\text{off}(\textbf{A})^2$ by $2|p|^2$, meaning that after a rotation we have (noting the amount of iterations the matrix has been through by a superscript):

\begin{align*}
\text{off}(\textbf{A}^{(1)})^2 = \text{off}(\textbf{A})^2 - 2|p|^2 \, ,
\end{align*}

By using the earlier inequality this gives us:

\begin{align*}
\text{off}(\textbf{A}^{(1)})^2 \leq (1 - \frac{2}{N(N-1)}) \text{off}(\textbf{A})^2 \\
\text{off}(\textbf{A}^{(1)}) \leq \sqrt{1 - \frac{2}{N(N-1)}} \text{off}(\textbf{A}) 
\end{align*}

This means that:

\begin{align*}
\text{off}(\textbf{A}^{(k)}) \leq \bigg(1 - \frac{2}{N(N-1)}\bigg)^{k/2} \text{off}(\textbf{A}) 
\end{align*}

As long as $N$ is large we can approximate:

\begin{align*}
1 - \frac{2}{N(N-1)} \approx e^{-\frac{2}{N(N-1)}}
\end{align*}

After $k$ iterations we then have the approximate relation:

\begin{align*}
\text{off}(\textbf{A}^{(k)}) \lesssim e^{-\frac{k}{N(N-1)}} \text{off}(\textbf{A}) 
\end{align*} 

This means that the convergence of the solution is dependent on several things. It is obviously dependent on the amount of iterations $k$, but it is also dependent on $\text{off}(\textbf{A})$ and $N$. If we assume $\text{off}(\textbf{A})$ to be something of reasonable size we have that the factor $e^{-\frac{k}{N(N-1)}}$ needs to be small. In order for this to be small we need $\frac{k}{N(N-1)}$ to be large, and for this to be larger than 1 even we need at least $k \geq N(N-1) \approx N^2$. Thus, as we assume $N$ to be a large number, $k = N^3$ would result in $e^{-\frac{k}{N(N-1)}}$ being a small number, and that is what we have set as a cap on the maximum amount of iterations the solver performs. It is worth noting that what we derived above is an approximation to the \textit{slowest rate possible} that the method can converge. Usually the solution converges faster than this. This also lets us put an approximate cap on the amount of FLOPs at $(12N + 29)N^3$. The method is thus highly computationally expensive. 


\subsection{Error sources and choices of parameters} \label{sec:III:b}

The three problems we are solving all contain a double derivative which we approximate. This causes an error which is dependent on the step length squared. The step length is proportional to $\rho_\text{max}$ and inversely proportional to $N$, so in order to minimize the step length we need $\rho_\text{max}$ to be significantly less than $N$. Very large $N$ will cause rounding error in $h$, but we encounter memory issues before this starts to be a problem. However this is not the only thing we need to take into consideration with larger $N$. As $N$ gets large, so does the amount of FLOPs needed to perform the algorithm. FLOPs inherently cause a small error as numbers generally cannot be represented exactly, and thus a large amount of FLOPs cause this error to accumulate. How this all balances out in the end is something we will review.

\subsubsection{Error sources when solving quantum mechanical problems} \label{sec:III:b:i} 

The quantum mechanical problems have another more specific error in loss of numerical precision on the diagonal elements of the matrices. In the case of one electron in a harmonic oscillator potential we have the diagonal elements:

\begin{align*}
d_i = \frac{2}{h^2} + \rho_i^2
\end{align*}

The factor $\frac{2}{h^2}$ is a constant, and $\rho_i^2$ varies. If they are not of a similar size we risk having a loss of numerical precision in setting up the matrix. In general the most notable issue here is if $h$ gets very small the constant factor grows very large, which means that we can't have $N$ being much larger than $\rho_\text{max}$. In general this means that there exists a value $N/\rho_\text{max}$ which has the most precise result. 

Similarly we have for the case with two electrons in a harmonic oscillator:

\begin{align*}
d_i &= \frac{2}{h^2} + \omega_r^2 \rho_i^2 + \frac{1}{\rho_i}
\end{align*}

In this case we introduce the factor $\omega_r$ and the extra term $1/\rho_i$. Generally most of the same arguments used in the previous case apply here as well, so we expect there to be a value $N/\rho_\text{max}$ which has the most precise the results. This will not be the same one as in the last case, and will also be different for different choices of $\omega_r$. 

\newpage

\section{Results} \label{sec:IV}

\subsection{Buckling beam} \label{sec:IV:a}

We calculated the first eigenvector numerically and plotted it against the analytical eigenvector with $N=200$. The plot is displayed in \hyperref[fig:IV:a:1]{Figure 1}. In order for them to be scaled similarly we chose to normalize both. Both the numerical and analytical value of the eigenvalue belonging to the eigenvector is written down in the legend text of the plot in \hyperref[fig:IV:a:1]{Figure 1}. Runs with a larger $N$ were also performed but they all produced similar results.

\begin{figure}[h!] \label{fig:IV:a:1}
\includegraphics[scale=0.6]{toeplitz.png}
\caption{Plot displaying the first eigenvector calculated numerically in the buckling beam problem with $N=200$ plotted together with the analytical result. Both the analytical and numerical solution have been normalized so they are scaled similarly. The plot also shows the numerical and analytic eigenvalue belonging to this solution in the legend text.}
\end{figure}

\subsection{Quantum harmonic oscillator with one electron} \label{sec:IV:b}

We calculated the smallest four eigenvalues both numerically and analytically. They are listed in \hyperref[table:IV:b:1]{Table I} along with the relative error between them. The parameters used in this run were $N=400$ and $\rho_\text{max} = 25$.

\begin{table}[h!] \label{table:IV:b:1}
\caption{Table containing numerical and analytical eigenvalues, and the relative error between them for the single electron in a harmonic oscillator potential. The parameters used were $N=400$ and $\rho_\text{max} = 25$.}
\begin{tabular}{|c|c|c|}
\hline 
Analytic & Numerical & Relative error \\
\hline
    3     &      2.999   &    $4.071 \times 10^{-4}$ \\
\hline
    7     &      6.994   &    $8.727 \times 10^{-4}$ \\
\hline
   11     &     10.985   &    $1.356 \times 10^{-3}$ \\
\hline
   15     &     14.972   &    $1.843 \times 10^{-3}$ \\
\hline
\end{tabular}
\end{table}


\subsection{Quantum harmonic oscillator with two electrons}\label{sec:IV:c}

We calculated the smallest eigenvalue for four different values of $\omega_r$ with $N=400$ and $\rho_\text{max} = 115.625$ both numerically and analytically. The eigenvalues and the relative error between them can be found in \hyperref[table:IV:c:1]{Table II}. 

\begin{table}[h!] \label{table:IV:c:1}
\caption{Table containing the numerical and analytical first eigenvalue (lowest energy), and the relative error between them for the problem with two electrons in a harmonic oscillator potential. The parameters used were $N=400$ and $\rho_\text{max} = 115.625$.}
\begin{tabular}{|c|c|c|c|}
\hline 
$\omega_r$ & Analytic & Numerical & Relative error \\
\hline
0.01 &    0     &      0.106  &    $6.966 \times 10^{-3}$ \\
\hline
0.5 &    2     &      2.189   &    $6.434 \times 10^{-2}$ \\
\hline
1 &   4     &     3.898   &    $7.623 \times 10^{-2}$ \\
\hline
5 &   14     &     14.118   &    $4.817 \times 10^{-3}$ \\
\hline
\end{tabular}
\end{table}

\newpage

\section{Discussion} \label{sec:V} 

\subsection{Buckling beam} \label{sec:V:a}

We can see in \hyperref[fig:IV:a:1]{Figure 1} that the numerically calculated eigenvector corresponds well with the analytically computed one. The numerical and analytical eigenvalues are also equal to the fourth digit, which together with the similar eigenvectors bode well for the accuracy of the method. There are two significant sources of errors here. One is from the approximation of the second derivative, and the other is from the FLOPs performed. This seems to indicate that both of these do not cause any significant error.

Now it is important to put this back into a physical context. The eigenvectors found here correspond to stable solutions to the wave equation. In theory there is an infinite amount of these solutions, but when searching numerically we are limited by the dimensionality of the matrix. 


\subsection{Quantum harmonic oscillator} \label{sec:V:b}

\section{Conclusion} \label{sec:VI}


\bibliography{kilder.bib}{}

\appendix
\section{Project files} \label{A}

\end{document}